apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring
  namespace: argocd
  annotations: { argocd.argoproj.io/sync-wave: "0" }
  finalizers: [resources-finalizer.argocd.argoproj.io]
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts          # chart repo
    chart: k8s-monitoring                                   # Alloy + Beyla + Loki + Tempo + Prom
    targetRevision: 2.*                                     # stick to v2 line
    helm:
      values: |
        # monitoring/values.yaml  ─── drop this into apps/monitoring/application.yaml → helm.values
        cluster:
          name: local-kind              # tag every metric/trace/log

        # ── FEATURES ─────────────────────────────────────────────────────────────
        clusterMetrics:
          enabled: true                 # <-– triggers kube-state-metrics, node exporter, etc.

        # ── COLLECTORS ───────────────────────────────────────────────────────────
        alloy-metrics:
          enabled: true                 # <-– REQUIRED for clusterMetrics feature

        beyla:                          # zero-code HTTP tracing via eBPF
          enabled: true
          extraEnvs:
            - name: BEYLA_OPEN_PORT
              value: "3000,5432"        # trace Next.js + Postgres traffic

        # ── DESTINATIONS (where data is stored) ─────────────────────────────────
        prometheus:
          enabled: true                 # deploy a Prometheus server inside this chart

        destinations:                   # tell the chart our Prom instance accepts metrics
          - name: localProm
            type: prometheus
            url: http://prometheus-server.monitoring.svc.cluster.local/api/v1/write
            metrics:
              enabled: true

        grafana:                         # optional UI
          enabled: true
          service:
            type: NodePort
            nodePort: 30001              # you already proxy this in kind-proxy

        # everything else (Loki, Tempo, etc.) can be added later


  destination:
    name: in-cluster
    namespace: monitoring
  syncPolicy:
    automated: { prune: true, selfHeal: true }
    syncOptions: ["CreateNamespace=true"]
